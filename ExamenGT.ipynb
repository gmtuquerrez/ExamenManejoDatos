{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22f6c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6dcd0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 84.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [00:01<00:00, 79.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 102.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 459/459 [00:04<00:00, 93.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 109.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 100.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 102.60it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"C:/Users/gerar/Desktop/UIDE/TratamientoDatos/examenFinal/ExamenManejoDatos/CarneDataset/test\"\n",
    "CATEGORIES = [\"CLASS_01\",\"CLASS_02\",\"CLASS_03\",\"CLASS_04\",\"CLASS_05\",\"CLASS_06\",\"CLASS_07\",\"CLASS_08\"]\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for category in CATEGORIES:  # read each category\n",
    "    path = os.path.join(DATADIR,category)  # create path for each category\n",
    "    class_num = CATEGORIES.index(category)  # get the classification \n",
    "    \n",
    "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c10c4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e314aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[202]\n",
      "   [189]\n",
      "   [188]\n",
      "   ...\n",
      "   [  3]\n",
      "   [  3]\n",
      "   [  4]]\n",
      "\n",
      "  [[187]\n",
      "   [187]\n",
      "   [187]\n",
      "   ...\n",
      "   [  2]\n",
      "   [  2]\n",
      "   [  3]]\n",
      "\n",
      "  [[185]\n",
      "   [188]\n",
      "   [187]\n",
      "   ...\n",
      "   [  2]\n",
      "   [  2]\n",
      "   [  2]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[112]\n",
      "   [ 83]\n",
      "   [108]\n",
      "   ...\n",
      "   [ 32]\n",
      "   [ 47]\n",
      "   [ 41]]\n",
      "\n",
      "  [[ 99]\n",
      "   [ 88]\n",
      "   [ 74]\n",
      "   ...\n",
      "   [ 60]\n",
      "   [ 35]\n",
      "   [ 39]]\n",
      "\n",
      "  [[ 89]\n",
      "   [104]\n",
      "   [ 87]\n",
      "   ...\n",
      "   [ 65]\n",
      "   [ 38]\n",
      "   [ 31]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8a34a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c906fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "18/18 [==============================] - 51s 3s/step - loss: -30063.2344 - categorical_accuracy: 1.0000 - val_loss: -154312.4219 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "18/18 [==============================] - 55s 3s/step - loss: -846903.0625 - categorical_accuracy: 1.0000 - val_loss: -2325948.5000 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "18/18 [==============================] - 56s 3s/step - loss: -6449223.5000 - categorical_accuracy: 1.0000 - val_loss: -13575791.0000 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a8be962d70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
